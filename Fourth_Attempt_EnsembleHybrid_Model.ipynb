{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pip install --upgrade scipy","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pip install --upgrade scikit-learn","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pip install scikeras[tensorflow]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.python.keras import layers\nfrom tensorflow.python.keras.callbacks import EarlyStopping\nfrom tensorflow.python.keras.layers import Dense, Activation, Dropout\nfrom tensorflow.python.keras.optimizers import adam_v2\nfrom tensorflow.python.keras.metrics import CategoricalAccuracy\nfrom tensorflow.python.keras.models import Sequential\nfrom keras.utils import to_categorical","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport sklearn\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.svm import SVC\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn.ensemble import StackingClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.datasets import make_classification\nfrom sklearn.metrics import accuracy_score\nfrom scikeras.wrappers import KerasClassifier","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"focussed_day1 = pd.read_csv(\"/kaggle/input/eeg-data-set/Day 3 - Focussed.csv\")\nfocussed_day1 = focussed_day1.dropna(axis=0)\ndrowsy_day1 = pd.read_csv(\"/kaggle/input/eeg-data-set/Day 3 - Semi-Focussed or Drowsy.csv\")\nunfocussed_day1 = pd.read_csv(\"/kaggle/input/eeg-data-set/Day 3 - Unfocussed or Sleeping.csv\")\ndrowsy_day1 = drowsy_day1.dropna(axis=0)\nunfocussed_day1 = unfocussed_day1.dropna(axis=0)\n\nfocussed_day2 = pd.read_csv(\"/kaggle/input/eeg-dataset-samples/Day 4 - Focussed.csv\")\nfocussed_day2 = focussed_day2.dropna(axis=0)\ndrowsy_day2 = pd.read_csv(\"/kaggle/input/eeg-dataset-samples/Day 4 - Semi-Focussed or Drowsy.csv\")\nunfocussed_day2 = pd.read_csv(\"/kaggle/input/eeg-dataset-samples/Day 4 - Unfocussed or Sleeping.csv\")\ndrowsy_day2 = drowsy_day2.dropna(axis=0)\nunfocussed_day2 = unfocussed_day2.dropna(axis=0)\n\nfocussed_day3 = pd.read_csv(\"/kaggle/input/eeg-dataset-samples/Day 5 - Focussed.csv\")\nfocussed_day3 = focussed_day3.dropna(axis=0)\ndrowsy_day3 = pd.read_csv(\"/kaggle/input/eeg-dataset-samples/Day 5 - Semi-Focussed or Drowsy.csv\")\nunfocussed_day3 = pd.read_csv(\"/kaggle/input/eeg-dataset-samples/Day 5 - Unfocussed or sleeping.csv\")\ndrowsy_day3 = drowsy_day3.dropna(axis=0)\nunfocussed_day3 = unfocussed_day3.dropna(axis=0)\n\nfocussed_day4 = pd.read_csv(\"/kaggle/input/eeg-dataset-samples/Day 6 - Focussed.csv\")\nfocussed_day4 = focussed_day4.dropna(axis=0)\ndrowsy_day4 = pd.read_csv(\"/kaggle/input/eeg-dataset-samples/Day 6 - Semi-Focussed or Drowsy.csv\")\nunfocussed_day4 = pd.read_csv(\"/kaggle/input/eeg-dataset-samples/Day 6 - Unfocussed or Sleeping.csv\")\ndrowsy_day4 = drowsy_day4.dropna(axis=0)\nunfocussed_day4 = unfocussed_day4.dropna(axis=0)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"merged = pd.concat([focussed_day1, drowsy_day1, unfocussed_day1, focussed_day2, drowsy_day2, unfocussed_day2,\n                   focussed_day3, drowsy_day3, unfocussed_day3, focussed_day4, drowsy_day4, unfocussed_day4])\nmerged","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_features = ['F7', 'F3', 'P7', 'O1', 'O2', 'P8', 'AF4']\ntest_value_features = ['Class']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train1 = merged[test_features]\ny_train1 = merged[test_value_features]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(X_train1, y_train1, test_size=0.2, random_state=0, stratify=y_train1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_train_encoded = pd.get_dummies(y_train)\ny_test_encoded = pd.get_dummies(y_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"scaler = StandardScaler()\nscaler.fit(X_train)\n\nX_train_scaled = scaler.transform(X_train)\nX_val_scaled = scaler.transform(X_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"early_stopping = EarlyStopping(\n    min_delta=0.001, \n    patience=20, \n    restore_best_weights=True,\n)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#svm_model = SVC(kernel='rbf', probability=True, max_iter=1000)\n#nn_model = MLPClassifier(hidden_layer_sizes=(1024, 1024, 1024, 1024), max_iter=2000, random_state=1, batch_size = 16384, learning_rate='adaptive', alpha=0.01, solver='adam')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def elu(x, alpha=1.0):\n    return tf.keras.layers.ELU(alpha=alpha)(x)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def neural_network_model():\n    nn_model = Sequential([\n    layers.Dense(1024, activation=elu, input_shape=[7]),  \n    layers.Dropout(0.3),\n    layers.Dense(1024, activation=elu),\n    layers.Dropout(0.3),\n    layers.Dense(1024, activation=elu),\n    layers.Dropout(0.3),\n    layers.Dense(1024, activation=elu),\n    layers.Dropout(0.3),\n    layers.Dense(1024, activation=elu),\n    layers.Dropout(0.3),\n    layers.Dense(3, activation='softmax')\n    ])\n    nn_model.compile(\n    optimizer='adam',\n    loss=tf.keras.losses.CategoricalCrossentropy(),\n    metrics=['accuracy'],\n    )\n    return nn_model\n    ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#nn_model.compile(\n#    optimizer='adam',\n#    loss=tf.keras.losses.CategoricalCrossentropy(),\n#    metrics=['accuracy'],\n#)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"nn_predictions = nn_model.fit(X_train_scaled, y_train_encoded, batch_size=32768, epochs=1000, validation_data = (X_val_scaled, y_test_encoded))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_train = y_train['Class'].to_numpy()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"svm_model.fit(X_train, y_train2)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_train.shape\n#type(y_train)\n#print(list(y_train['Class']))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#max_epochs_ensemble_model = 1000","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"final_estimator_choice = LogisticRegression()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model1 = KerasClassifier(build_fn = neural_network_model, epochs = 100, verbose=1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"svm_model = SVC(kernel='rbf', probability=True, max_iter = 100)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"stacked_model = StackingClassifier(estimators=[('SVM', svm_model), ('NN', model1)], \n                                   final_estimator = final_estimator_choice)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"param_grid = {\n    'SVM__C': [0.5, 1.0, 5.0, 10.0, 50.0, 100.0],\n}","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"grid_search = GridSearchCV(stacked_model, param_grid, cv=5)\ngrid_search.fit(X_train, y_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"best_C = grid_search.best_params_['SVM__C']\nprint(\"Best C:\", best_C)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"best_C = 50;","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"svm_model = SVC(kernel='rbf', C=best_C, probability=True, max_iter = 100)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"new_stacked_model = StackingClassifier(estimators=[('SVM', svm_model), ('NN', model1)], \n                                   final_estimator = final_estimator_choice)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#final_estimator = LogisticRegression()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"new_stacked_model.fit(X_train, y_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"accuracy = new_stacked_model.score(X_test, y_test)\nprint(\"Stacking Ensemble Model Accuracy:\", accuracy)","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}